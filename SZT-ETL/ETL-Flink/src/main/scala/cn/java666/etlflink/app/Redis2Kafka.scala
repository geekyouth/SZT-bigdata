package cn.java666.etlflink.app

import java.util.Properties

import cn.java666.etlflink.source.MyRedisSourceFun
import org.apache.flink.api.common.serialization.SimpleStringSchema
import org.apache.flink.streaming.api.scala._
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011

import scala.util.Random

/**
 * @author Geek
 * @date 2020-04-14 04:35:36
 *
 * redis szt:pageJson æŠ½å–æºæ•°æ®åˆ° kafka
 *
 */
object Redis2Kafka {
	def main(args: Array[String]): Unit = {
		val env = StreamExecutionEnvironment.getExecutionEnvironment
		env.setParallelism(1)
		
		val prop = new Properties
		prop.load(ClassLoader.getSystemResourceAsStream("kafka.properties"))
		
		val s = env.addSource[String](new MyRedisSourceFun)
			.map(x => {
				// TODO å‡è£…ä¼‘æ¯ä¸€ä¼šï¼Œå¦‚æœå®¢æˆ·è§‰å¾—é€Ÿåº¦å¤ªæ…¢ï¼Œå¯ä»¥åŠ é’±ä¼˜åŒ–ï¼ï¼ï¼ä½†æ˜¯è¿™é‡Œæˆ‘ä»¬çœŸçš„éœ€è¦ä¼‘æ¯ï¼Œå› ä¸ºé€Ÿåº¦å¤ªå¿«æœºå™¨ä¼šå¡ä½ğŸ™„ğŸ™„ğŸ™„ç”šè‡³å´©æºƒ
				//Thread.sleep(Random.nextInt(10)) 
				x
			})
		
		s.addSink(
			new FlinkKafkaProducer011(
				prop.getProperty("kafka.broker-list")
				, prop.getProperty("kafka.producer.topic")
				, new SimpleStringSchema()
			)
		)
		
		env.execute("Redis2Kafka")
	}
}
